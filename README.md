# Week 3 (6/2/25 - 6/8/25)

During Week 3, I read over some of the other projects and offered feedback.

On my own project, I did further analysis in a JuPyter notebook and set up some preliminary functions to work with the data. Below is a snapshot from the notebook in which I generate a plot of all ash trees (my primary pollen allergen) in St. Louis:

![A plot of all ash trees in St. Louis, MO](images/stl_ash_trees_plot.png)

This visual was helpful to me in verifying that the lat/lon is working correctly and that the data is what I'd expect. In this case, the ash trees are spread all over the city, so a plot of them reveals essentially a map of St. Louis. Also visible is the "central corridor" running east to west through the middle, which is the most urban part of the city and thus the area with the fewest trees. Also, since the dataset is limited to public roads, various campuses and large parks are also visible as "holes" in the data. These holes may be something to come back to, but for now the point of this and other data exploration is just to get a feel for it and how I might best make use of it down the line.

Right now, there are no blocks to progress. The main future block that I can currently anticipate is learning Flask in order to implement a back-end to the site - Python/Pandas to manipulate the data and HTML/JS for the front-end are not new to me.

Like last week, I need to improve on uploading things to GitHub to keep it organized as well as document progress. Already I have mistakenly deleted code in a way that would be trivial to fix with a version history using Git.


# Week 2 (5/26/25 - 6/1/25)

During Week 2, I formalized my project into a project proposal and did some preliminary analysis of the tree geographic data that my project will be built upon.

This week I plan to continue the data analysis. Part of the preliminary step is a proof of concept for calculating allergen density given the various toggles that will be available to the user. Additionally, the data will need a bit of light cleaning to remove missing or irrelevant values. Just getting a feel for how the fields work though will be important for efficiently implementing what I need.

There are no blocks at this time. Right now I am working with an extract of the data inside a JuPyter notebook, so no new tools to learn or anything (yet).

To improve the process over last week, I think organizing things in GitHub will be helpful going forward to have everything in one place and clearly laid out.


# Week 1 (5/19/25 - 5/25/25)

During Week 1, I familiarized myself with the course structure, got my bearings on GitHub pages, and started scoping out my project plans. 

I don't want to overshoot the project parameters by setting goals that are too ambitious nor undershoot and end up completing it too soon. To account for this, I plan to structure my project as a minimal viable product followed by incremental feature additions. 
This way the core of the project will definitely be completed by the end of the course, but there will still be room to keep working if there are still weeks remaining at the end.

So far, the main impediment is just ironing out the project plan (which I plan do to this week) and learning the different tools/technologies necessary to pull it all together.
I am taking two courses this semester, and my usual practice in this situation is to finish the coursework for each in sequence, but going forward I think it will make more sense to work on portions of each so that this course doesn't end up squished into the end of the week.
